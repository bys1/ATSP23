{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d338545",
   "metadata": {},
   "source": [
    "## Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import pickle\n",
    "import warnings\n",
    "import math\n",
    "import base64\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import zmq\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Configurations and settings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=False)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# Assuming UTF-8 encoding, change to something else if you need to\n",
    "base64.b64encode(\"password\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2a93f",
   "metadata": {},
   "source": [
    "## Discriminator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, no_of_channels=1, disc_dim=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "                nn.Conv2d(in_channels=no_of_channels, out_channels=disc_dim, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=disc_dim, out_channels=disc_dim * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(disc_dim * 2, track_running_stats=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=disc_dim * 2, out_channels=disc_dim * 4, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(disc_dim * 4, track_running_stats=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=disc_dim * 4, out_channels=1, \n",
    "                          kernel_size=4, stride=1, padding=0, bias=False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        forward pass of the discriminator\n",
    "        Input is an image tensor, \n",
    "        returns a 1-dimension tensor representing image as    \n",
    "        fake/real.\n",
    "        '''\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5ac62",
   "metadata": {},
   "source": [
    "## Generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layers = nn.Sequential(*[\n",
    "                                      self.conv_block(100, 128, padding=0),\n",
    "                                      self.conv_block(128, 64, stride=2, ks=3),\n",
    "                                      self.conv_block(64, 32, stride=2),\n",
    "                                      self.conv_block(32, 1, stride=2, bn=False, out_layer=True)\n",
    "        ])\n",
    "        # Our input is 100 dimensional random noise\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_block(in_c, out_c, out_layer=False, ks=4, stride=1, padding=1, bias=False, bn=True):\n",
    "        l = [nn.ConvTranspose2d(in_c, out_c, ks, stride=stride, padding=padding, bias=bias)]\n",
    "        if bn: l.append(nn.BatchNorm2d(out_c, track_running_stats=False))\n",
    "        if out_layer: l.append(nn.Tanh())\n",
    "        else: l.append(nn.ReLU(True))\n",
    "        return nn.Sequential(*l)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f694c934",
   "metadata": {},
   "source": [
    "## Declaring method to convert the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ce29c",
   "metadata": {},
   "source": [
    "## Running ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ccca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1 \n",
    "G = Generator()\n",
    "# print(G)\n",
    "D = Discriminator()\n",
    "\n",
    "D.load_state_dict(torch.load('Dis_HE.ckpt'))\n",
    "discrimiator = D.state_dict()\n",
    "# for k, v in discrimiator.items():\n",
    "#     print(k)\n",
    "    \n",
    "G.load_state_dict(torch.load('Gen_HE.ckpt'))\n",
    "generator = G.state_dict()\n",
    "# for k, v in generator.items():\n",
    "#     print(k)\n",
    "\n",
    "vals111 = []\n",
    "keys = []\n",
    "vals = []\n",
    "for k, v in discrimiator.items():\n",
    "    keys.append(k)\n",
    "    vals.append(v)\n",
    "    a = v.numpy()\n",
    "    vals111.append(a.shape)\n",
    "# print(vals111)\n",
    "# vals111 = numpy.array(vals)   \n",
    "# keys = numpy.array(keys)\n",
    "# vals = numpy.array(vals)\n",
    "\n",
    "keys1 = []\n",
    "vals1 = []\n",
    "for k1, v1 in generator.items():\n",
    "    keys1.append(k1)\n",
    "    vals1.append(v1)\n",
    "# keys1 = numpy.array(keys1)\n",
    "# vals1 = numpy.array(vals1)\n",
    "\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model2.state_dict():\n",
    "#     print(torch.numel(model2.state_dict()[param_tensor]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7f42c",
   "metadata": {},
   "source": [
    "## Declaring methods to print the elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elapsed_time_total(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Total Traning Time: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "                .format(int(hours),int(minutes),seconds))\n",
    "\n",
    "def elapsed_time_avg(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Averaging overhead: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "                .format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6241428",
   "metadata": {},
   "source": [
    "## Declaring methods to save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(file_name, data):\n",
    "    if type(data) == bytes:\n",
    "        #bytes to base64\n",
    "        data = base64.b64encode(data)\n",
    "         \n",
    "    with open(file_name, 'wb') as f: \n",
    "        f.write(data)\n",
    " \n",
    "def read_data(file_name):\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    #base64 to bytes\n",
    "    return base64.b64decode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e539eb",
   "metadata": {},
   "source": [
    "## Main server loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6ff5e",
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "global data_list\n",
    "global client_num\n",
    "\n",
    "client_num = 0\n",
    "\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.ROUTER)\n",
    "socket.bind(\"tcp://*:5555\")\n",
    "\n",
    "pub_socket = context.socket(zmq.PUB)\n",
    "pub_socket.bind(\"tcp://*:5557\")\n",
    "\n",
    "start_total = time.time()\n",
    "print(\"The server is running now!\")\n",
    "\n",
    "c = 0\n",
    "data_list = []\n",
    "loaded_enc = []\n",
    "loaded_enc_tmp = []\n",
    "cipher1 = []\n",
    "cipher2 = []\n",
    "sum_ = 0\n",
    "\n",
    "data_list_dicriminator = []\n",
    "data_list_generator = []\n",
    "sum_1 = 0\n",
    "sum_2 = 0\n",
    "\n",
    "client_num_ = 10\n",
    "while c < client_num_ * 10:\n",
    "#     print(G)\n",
    "    ident1, msg1 = socket.recv_multipart()\n",
    "    ident2, msg2 = socket.recv_multipart()\n",
    "        \n",
    "    string = b\"New\"\n",
    "    \n",
    "    if string == msg1 and string == msg2: \n",
    "        client_num = client_num + 1\n",
    "        \n",
    "        message1 = pickle.dumps(vals)\n",
    "        socket.send_multipart([ident1, message1])\n",
    "        \n",
    "        message2 = pickle.dumps(vals1)\n",
    "        socket.send_multipart([ident2, message2])\n",
    "        \n",
    "        print(\"Base model sent to the new client!\")\n",
    "    else: \n",
    "        print(\"Training round started\")\n",
    "        \n",
    "        message1 = pickle.loads(msg1)\n",
    "        message2 = pickle.loads(msg2)\n",
    "        \n",
    "        if len(message1) == 8:\n",
    "            data_list_dicriminator.append(message1)\n",
    "        else:\n",
    "            data_list_generator.append(message1)\n",
    "        \n",
    "        if len(message2) == 8:\n",
    "            data_list_dicriminator.append(message2)\n",
    "        else:\n",
    "            data_list_generator.append(message2)\n",
    "            \n",
    "        print(len(data_list_dicriminator))\n",
    "        print(len(data_list_generator))\n",
    "\n",
    "        if len(data_list_dicriminator) == client_num_ and len(data_list_generator) == client_num_:\n",
    "            print(\"Enough data recevied\")\n",
    "            \n",
    "            start_avg = time.time()\n",
    "        \n",
    "            cipher1 = sum(data_list_dicriminator) / client_num_\n",
    "            cipher2 = sum(data_list_generator) / client_num_\n",
    "\n",
    "            print(\"Avgg generator encrypted computed\")\n",
    "            end_avg = time.time()\n",
    "            elapsed_time_avg(start_avg, end_avg) \n",
    "            \n",
    "            message1 = pickle.dumps(cipher1)\n",
    "            print(\"Plain data size in bytes {}\".format(convert_size(len(message1))))\n",
    "\n",
    "            message2 = pickle.dumps(cipher2)\n",
    "            print(\"Avaraged dicriminator {}\".format(convert_size(len(message2))))\n",
    "            \n",
    "            pub_socket.send(message1)\n",
    "            pub_socket.send(message2)\n",
    "            \n",
    "            print(\"Sent!\")\n",
    "            \n",
    "            cipher1 = []\n",
    "            cipher2 = []\n",
    "            sum_1 = 0\n",
    "            sum_2 = 0\n",
    "            sum_final1 = 0\n",
    "            sum_final2 = 0\n",
    "            data_list_dicriminator = []\n",
    "            data_list_generator = []\n",
    "\n",
    "        c = c + 1\n",
    "        \n",
    "end_total = time.time()\n",
    "elapsed_time_total(start_total, end_total)\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
